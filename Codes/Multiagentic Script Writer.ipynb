{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":281649,"sourceType":"modelInstanceVersion","isSourceIdPinned":true,"modelInstanceId":241319,"modelId":222398}],"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install pyautogen\n!pip install autogen-agentchat~=0.2\n!pip install --use-deprecated=legacy-resolver pyautogen\n!pip install --use-deprecated=legacy-resolver autogen-agentchat~=0.2","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-04-07T14:03:20.045478Z","iopub.execute_input":"2025-04-07T14:03:20.045836Z","iopub.status.idle":"2025-04-07T14:03:59.790326Z","shell.execute_reply.started":"2025-04-07T14:03:20.045808Z","shell.execute_reply":"2025-04-07T14:03:59.789311Z"}},"outputs":[{"name":"stdout","text":"Collecting pyautogen\n  Downloading pyautogen-0.8.5-py3-none-any.whl.metadata (30 kB)\nRequirement already satisfied: anyio<5.0.0,>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from pyautogen) (3.7.1)\nCollecting asyncer==0.0.8 (from pyautogen)\n  Downloading asyncer-0.0.8-py3-none-any.whl.metadata (6.7 kB)\nCollecting diskcache (from pyautogen)\n  Downloading diskcache-5.6.3-py3-none-any.whl.metadata (20 kB)\nRequirement already satisfied: docker in /usr/local/lib/python3.10/dist-packages (from pyautogen) (7.1.0)\nRequirement already satisfied: httpx<1,>=0.28.1 in /usr/local/lib/python3.10/dist-packages (from pyautogen) (0.28.1)\nRequirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from pyautogen) (24.2)\nRequirement already satisfied: pydantic<3,>=2.6.1 in /usr/local/lib/python3.10/dist-packages (from pyautogen) (2.11.0a2)\nCollecting python-dotenv (from pyautogen)\n  Downloading python_dotenv-1.1.0-py3-none-any.whl.metadata (24 kB)\nRequirement already satisfied: termcolor in /usr/local/lib/python3.10/dist-packages (from pyautogen) (2.5.0)\nRequirement already satisfied: tiktoken in /usr/local/lib/python3.10/dist-packages (from pyautogen) (0.9.0)\nRequirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5.0.0,>=3.0.0->pyautogen) (3.10)\nRequirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.10/dist-packages (from anyio<5.0.0,>=3.0.0->pyautogen) (1.3.1)\nRequirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5.0.0,>=3.0.0->pyautogen) (1.2.2)\nRequirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.28.1->pyautogen) (2025.1.31)\nRequirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.28.1->pyautogen) (1.0.7)\nRequirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx<1,>=0.28.1->pyautogen) (0.14.0)\nRequirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=2.6.1->pyautogen) (0.7.0)\nRequirement already satisfied: pydantic-core==2.29.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=2.6.1->pyautogen) (2.29.0)\nRequirement already satisfied: typing-extensions>=4.12.2 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=2.6.1->pyautogen) (4.12.2)\nRequirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.10/dist-packages (from docker->pyautogen) (2.32.3)\nRequirement already satisfied: urllib3>=1.26.0 in /usr/local/lib/python3.10/dist-packages (from docker->pyautogen) (2.3.0)\nRequirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.10/dist-packages (from tiktoken->pyautogen) (2024.11.6)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->docker->pyautogen) (3.4.1)\nDownloading pyautogen-0.8.5-py3-none-any.whl (730 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m730.4/730.4 kB\u001b[0m \u001b[31m12.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[?25hDownloading asyncer-0.0.8-py3-none-any.whl (9.2 kB)\nDownloading diskcache-5.6.3-py3-none-any.whl (45 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.5/45.5 kB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading python_dotenv-1.1.0-py3-none-any.whl (20 kB)\nInstalling collected packages: python-dotenv, diskcache, asyncer, pyautogen\nSuccessfully installed asyncer-0.0.8 diskcache-5.6.3 pyautogen-0.8.5 python-dotenv-1.1.0\nCollecting autogen-agentchat~=0.2\n  Downloading autogen_agentchat-0.5.1-py3-none-any.whl.metadata (2.5 kB)\nCollecting autogen-core==0.5.1 (from autogen-agentchat~=0.2)\n  Downloading autogen_core-0.5.1-py3-none-any.whl.metadata (2.3 kB)\nCollecting jsonref~=1.1.0 (from autogen-core==0.5.1->autogen-agentchat~=0.2)\n  Downloading jsonref-1.1.0-py3-none-any.whl.metadata (2.7 kB)\nRequirement already satisfied: opentelemetry-api>=1.27.0 in /usr/local/lib/python3.10/dist-packages (from autogen-core==0.5.1->autogen-agentchat~=0.2) (1.29.0)\nRequirement already satisfied: pillow>=11.0.0 in /usr/local/lib/python3.10/dist-packages (from autogen-core==0.5.1->autogen-agentchat~=0.2) (11.0.0)\nCollecting protobuf~=5.29.3 (from autogen-core==0.5.1->autogen-agentchat~=0.2)\n  Downloading protobuf-5.29.4-cp38-abi3-manylinux2014_x86_64.whl.metadata (592 bytes)\nRequirement already satisfied: pydantic<3.0.0,>=2.10.0 in /usr/local/lib/python3.10/dist-packages (from autogen-core==0.5.1->autogen-agentchat~=0.2) (2.11.0a2)\nRequirement already satisfied: typing-extensions>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from autogen-core==0.5.1->autogen-agentchat~=0.2) (4.12.2)\nRequirement already satisfied: deprecated>=1.2.6 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-api>=1.27.0->autogen-core==0.5.1->autogen-agentchat~=0.2) (1.2.15)\nRequirement already satisfied: importlib-metadata<=8.5.0,>=6.0 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-api>=1.27.0->autogen-core==0.5.1->autogen-agentchat~=0.2) (8.5.0)\nRequirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3.0.0,>=2.10.0->autogen-core==0.5.1->autogen-agentchat~=0.2) (0.7.0)\nRequirement already satisfied: pydantic-core==2.29.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3.0.0,>=2.10.0->autogen-core==0.5.1->autogen-agentchat~=0.2) (2.29.0)\nRequirement already satisfied: wrapt<2,>=1.10 in /usr/local/lib/python3.10/dist-packages (from deprecated>=1.2.6->opentelemetry-api>=1.27.0->autogen-core==0.5.1->autogen-agentchat~=0.2) (1.17.0)\nRequirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.10/dist-packages (from importlib-metadata<=8.5.0,>=6.0->opentelemetry-api>=1.27.0->autogen-core==0.5.1->autogen-agentchat~=0.2) (3.21.0)\nDownloading autogen_agentchat-0.5.1-py3-none-any.whl (80 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m80.8/80.8 kB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading autogen_core-0.5.1-py3-none-any.whl (86 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.6/86.6 kB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading jsonref-1.1.0-py3-none-any.whl (9.4 kB)\nDownloading protobuf-5.29.4-cp38-abi3-manylinux2014_x86_64.whl (319 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m319.7/319.7 kB\u001b[0m \u001b[31m10.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hInstalling collected packages: protobuf, jsonref, autogen-core, autogen-agentchat\n  Attempting uninstall: protobuf\n    Found existing installation: protobuf 3.20.3\n    Uninstalling protobuf-3.20.3:\n      Successfully uninstalled protobuf-3.20.3\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\ngoogle-api-core 1.34.1 requires protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<4.0.0dev,>=3.19.5, but you have protobuf 5.29.4 which is incompatible.\ngoogle-cloud-bigtable 2.27.0 requires google-api-core[grpc]<3.0.0dev,>=2.16.0, but you have google-api-core 1.34.1 which is incompatible.\ngoogle-cloud-translate 3.12.1 requires protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.19.5, but you have protobuf 5.29.4 which is incompatible.\npandas-gbq 0.25.0 requires google-api-core<3.0.0dev,>=2.10.2, but you have google-api-core 1.34.1 which is incompatible.\ntensorflow 2.17.1 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3, but you have protobuf 5.29.4 which is incompatible.\ntensorflow-decision-forests 1.10.0 requires tensorflow==2.17.0, but you have tensorflow 2.17.1 which is incompatible.\ntensorflow-metadata 1.13.1 requires protobuf<5,>=3.20.3, but you have protobuf 5.29.4 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed autogen-agentchat-0.5.1 autogen-core-0.5.1 jsonref-1.1.0 protobuf-5.29.4\nRequirement already satisfied: pyautogen in /usr/local/lib/python3.10/dist-packages (0.8.5)\nRequirement already satisfied: anyio<5.0.0,>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from pyautogen) (3.7.1)\nRequirement already satisfied: asyncer==0.0.8 in /usr/local/lib/python3.10/dist-packages (from pyautogen) (0.0.8)\nRequirement already satisfied: diskcache in /usr/local/lib/python3.10/dist-packages (from pyautogen) (5.6.3)\nRequirement already satisfied: docker in /usr/local/lib/python3.10/dist-packages (from pyautogen) (7.1.0)\nRequirement already satisfied: httpx<1,>=0.28.1 in /usr/local/lib/python3.10/dist-packages (from pyautogen) (0.28.1)\nRequirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from pyautogen) (24.2)\nRequirement already satisfied: pydantic<3,>=2.6.1 in /usr/local/lib/python3.10/dist-packages (from pyautogen) (2.11.0a2)\nRequirement already satisfied: python-dotenv in /usr/local/lib/python3.10/dist-packages (from pyautogen) (1.1.0)\nRequirement already satisfied: termcolor in /usr/local/lib/python3.10/dist-packages (from pyautogen) (2.5.0)\nRequirement already satisfied: tiktoken in /usr/local/lib/python3.10/dist-packages (from pyautogen) (0.9.0)\nRequirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5.0.0,>=3.0.0->pyautogen) (3.10)\nRequirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.10/dist-packages (from anyio<5.0.0,>=3.0.0->pyautogen) (1.3.1)\nRequirement already satisfied: exceptiongroup; python_version < \"3.11\" in /usr/local/lib/python3.10/dist-packages (from anyio<5.0.0,>=3.0.0->pyautogen) (1.2.2)\nRequirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.10/dist-packages (from docker->pyautogen) (2.32.3)\nRequirement already satisfied: urllib3>=1.26.0 in /usr/local/lib/python3.10/dist-packages (from docker->pyautogen) (2.3.0)\nRequirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.28.1->pyautogen) (2025.1.31)\nRequirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.28.1->pyautogen) (1.0.7)\nRequirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=2.6.1->pyautogen) (0.7.0)\nRequirement already satisfied: pydantic-core==2.29.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=2.6.1->pyautogen) (2.29.0)\nRequirement already satisfied: typing-extensions>=4.12.2 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=2.6.1->pyautogen) (4.12.2)\nRequirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.10/dist-packages (from tiktoken->pyautogen) (2024.11.6)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->docker->pyautogen) (3.4.1)\nRequirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx<1,>=0.28.1->pyautogen) (0.14.0)\nRequirement already satisfied: autogen-agentchat~=0.2 in /usr/local/lib/python3.10/dist-packages (0.5.1)\nRequirement already satisfied: autogen-core==0.5.1 in /usr/local/lib/python3.10/dist-packages (from autogen-agentchat~=0.2) (0.5.1)\nRequirement already satisfied: jsonref~=1.1.0 in /usr/local/lib/python3.10/dist-packages (from autogen-core==0.5.1->autogen-agentchat~=0.2) (1.1.0)\nRequirement already satisfied: opentelemetry-api>=1.27.0 in /usr/local/lib/python3.10/dist-packages (from autogen-core==0.5.1->autogen-agentchat~=0.2) (1.29.0)\nRequirement already satisfied: pillow>=11.0.0 in /usr/local/lib/python3.10/dist-packages (from autogen-core==0.5.1->autogen-agentchat~=0.2) (11.0.0)\nRequirement already satisfied: protobuf~=5.29.3 in /usr/local/lib/python3.10/dist-packages (from autogen-core==0.5.1->autogen-agentchat~=0.2) (5.29.4)\nRequirement already satisfied: pydantic<3.0.0,>=2.10.0 in /usr/local/lib/python3.10/dist-packages (from autogen-core==0.5.1->autogen-agentchat~=0.2) (2.11.0a2)\nRequirement already satisfied: typing-extensions>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from autogen-core==0.5.1->autogen-agentchat~=0.2) (4.12.2)\nRequirement already satisfied: deprecated>=1.2.6 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-api>=1.27.0->autogen-core==0.5.1->autogen-agentchat~=0.2) (1.2.15)\nRequirement already satisfied: importlib-metadata<=8.5.0,>=6.0 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-api>=1.27.0->autogen-core==0.5.1->autogen-agentchat~=0.2) (8.5.0)\nRequirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3.0.0,>=2.10.0->autogen-core==0.5.1->autogen-agentchat~=0.2) (0.7.0)\nRequirement already satisfied: pydantic-core==2.29.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3.0.0,>=2.10.0->autogen-core==0.5.1->autogen-agentchat~=0.2) (2.29.0)\nRequirement already satisfied: wrapt<2,>=1.10 in /usr/local/lib/python3.10/dist-packages (from deprecated>=1.2.6->opentelemetry-api>=1.27.0->autogen-core==0.5.1->autogen-agentchat~=0.2) (1.17.0)\nRequirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.10/dist-packages (from importlib-metadata<=8.5.0,>=6.0->opentelemetry-api>=1.27.0->autogen-core==0.5.1->autogen-agentchat~=0.2) (3.21.0)\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"pip install autogen[openai]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-07T14:03:59.791868Z","iopub.execute_input":"2025-04-07T14:03:59.792247Z","iopub.status.idle":"2025-04-07T14:04:06.047904Z","shell.execute_reply.started":"2025-04-07T14:03:59.792212Z","shell.execute_reply":"2025-04-07T14:04:06.046827Z"}},"outputs":[{"name":"stdout","text":"Collecting autogen[openai]\n  Downloading autogen-0.8.5-py3-none-any.whl.metadata (20 kB)\nRequirement already satisfied: pyautogen==0.8.5 in /usr/local/lib/python3.10/dist-packages (from autogen[openai]) (0.8.5)\nRequirement already satisfied: anyio<5.0.0,>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from pyautogen==0.8.5->autogen[openai]) (3.7.1)\nRequirement already satisfied: asyncer==0.0.8 in /usr/local/lib/python3.10/dist-packages (from pyautogen==0.8.5->autogen[openai]) (0.0.8)\nRequirement already satisfied: diskcache in /usr/local/lib/python3.10/dist-packages (from pyautogen==0.8.5->autogen[openai]) (5.6.3)\nRequirement already satisfied: docker in /usr/local/lib/python3.10/dist-packages (from pyautogen==0.8.5->autogen[openai]) (7.1.0)\nRequirement already satisfied: httpx<1,>=0.28.1 in /usr/local/lib/python3.10/dist-packages (from pyautogen==0.8.5->autogen[openai]) (0.28.1)\nRequirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from pyautogen==0.8.5->autogen[openai]) (24.2)\nRequirement already satisfied: pydantic<3,>=2.6.1 in /usr/local/lib/python3.10/dist-packages (from pyautogen==0.8.5->autogen[openai]) (2.11.0a2)\nRequirement already satisfied: python-dotenv in /usr/local/lib/python3.10/dist-packages (from pyautogen==0.8.5->autogen[openai]) (1.1.0)\nRequirement already satisfied: termcolor in /usr/local/lib/python3.10/dist-packages (from pyautogen==0.8.5->autogen[openai]) (2.5.0)\nRequirement already satisfied: tiktoken in /usr/local/lib/python3.10/dist-packages (from pyautogen==0.8.5->autogen[openai]) (0.9.0)\nCollecting openai>=1.66.2 (from pyautogen[openai]==0.8.5; extra == \"openai\"->autogen[openai])\n  Downloading openai-1.70.0-py3-none-any.whl.metadata (25 kB)\nRequirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5.0.0,>=3.0.0->pyautogen==0.8.5->autogen[openai]) (3.10)\nRequirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.10/dist-packages (from anyio<5.0.0,>=3.0.0->pyautogen==0.8.5->autogen[openai]) (1.3.1)\nRequirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5.0.0,>=3.0.0->pyautogen==0.8.5->autogen[openai]) (1.2.2)\nRequirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.28.1->pyautogen==0.8.5->autogen[openai]) (2025.1.31)\nRequirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.28.1->pyautogen==0.8.5->autogen[openai]) (1.0.7)\nRequirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx<1,>=0.28.1->pyautogen==0.8.5->autogen[openai]) (0.14.0)\nRequirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.10/dist-packages (from openai>=1.66.2->pyautogen[openai]==0.8.5; extra == \"openai\"->autogen[openai]) (1.9.0)\nRequirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from openai>=1.66.2->pyautogen[openai]==0.8.5; extra == \"openai\"->autogen[openai]) (0.8.2)\nRequirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai>=1.66.2->pyautogen[openai]==0.8.5; extra == \"openai\"->autogen[openai]) (4.67.1)\nRequirement already satisfied: typing-extensions<5,>=4.11 in /usr/local/lib/python3.10/dist-packages (from openai>=1.66.2->pyautogen[openai]==0.8.5; extra == \"openai\"->autogen[openai]) (4.12.2)\nRequirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=2.6.1->pyautogen==0.8.5->autogen[openai]) (0.7.0)\nRequirement already satisfied: pydantic-core==2.29.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=2.6.1->pyautogen==0.8.5->autogen[openai]) (2.29.0)\nRequirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.10/dist-packages (from docker->pyautogen==0.8.5->autogen[openai]) (2.32.3)\nRequirement already satisfied: urllib3>=1.26.0 in /usr/local/lib/python3.10/dist-packages (from docker->pyautogen==0.8.5->autogen[openai]) (2.3.0)\nRequirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.10/dist-packages (from tiktoken->pyautogen==0.8.5->autogen[openai]) (2024.11.6)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->docker->pyautogen==0.8.5->autogen[openai]) (3.4.1)\nDownloading autogen-0.8.5-py3-none-any.whl (12 kB)\nDownloading openai-1.70.0-py3-none-any.whl (599 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m599.1/599.1 kB\u001b[0m \u001b[31m10.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[?25hInstalling collected packages: openai, autogen\n  Attempting uninstall: openai\n    Found existing installation: openai 1.57.4\n    Uninstalling openai-1.57.4:\n      Successfully uninstalled openai-1.57.4\nSuccessfully installed autogen-0.8.5 openai-1.70.0\nNote: you may need to restart the kernel to use updated packages.\n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"import os\nos.environ[\"OPENAI_API_KEY\"] = \"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\" # replace \"YOUR_API_KEY\" with your actual API key\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-07T14:04:06.049653Z","iopub.execute_input":"2025-04-07T14:04:06.049953Z","iopub.status.idle":"2025-04-07T14:04:06.054262Z","shell.execute_reply.started":"2025-04-07T14:04:06.049926Z","shell.execute_reply":"2025-04-07T14:04:06.053234Z"}},"outputs":[],"execution_count":4},{"cell_type":"code","source":"!pip install gemma","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-07T14:04:39.405572Z","iopub.execute_input":"2025-04-07T14:04:39.405926Z","iopub.status.idle":"2025-04-07T14:04:44.559182Z","shell.execute_reply.started":"2025-04-07T14:04:39.405898Z","shell.execute_reply":"2025-04-07T14:04:44.558180Z"}},"outputs":[{"name":"stdout","text":"Collecting gemma\n  Downloading gemma-1.2.2-py3-none-any.whl.metadata (856 bytes)\nCollecting dataclasses (from gemma)\n  Downloading dataclasses-0.6-py3-none-any.whl.metadata (3.0 kB)\nDownloading gemma-1.2.2-py3-none-any.whl (28 kB)\nDownloading dataclasses-0.6-py3-none-any.whl (14 kB)\nInstalling collected packages: dataclasses, gemma\nSuccessfully installed dataclasses-0.6 gemma-1.2.2\n","output_type":"stream"}],"execution_count":6},{"cell_type":"code","source":"!pip install gemma.config","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-07T14:05:15.530059Z","iopub.execute_input":"2025-04-07T14:05:15.530456Z","iopub.status.idle":"2025-04-07T14:05:16.926648Z","shell.execute_reply.started":"2025-04-07T14:05:15.530425Z","shell.execute_reply":"2025-04-07T14:05:16.925472Z"}},"outputs":[{"name":"stdout","text":"\u001b[31mERROR: Could not find a version that satisfies the requirement gemma.config (from versions: none)\u001b[0m\u001b[31m\n\u001b[0m\u001b[31mERROR: No matching distribution found for gemma.config\u001b[0m\u001b[31m\n\u001b[0m","output_type":"stream"}],"execution_count":8},{"cell_type":"code","source":"config_list_gpt4 = [\n    {\n        'model': 'gpt-4',\n        'api_key': os.environ.get(\"OPENAI_API_KEY\"),\n    }\n]\n\nllm_config_gpt4 = {\n    'seed': 42,\n    'config_list': config_list_gpt4,\n    'temperature': 0\n}\n\n# -----------------------------------------------------------------------\n# Agent Definitions\n# -----------------------------------------------------------------------\n\n# Function to generate text using Gemma\ndef generate_gemma_text(prompt):\n    \"\"\"Generates text using the Gemma model.\"\"\"\n    input_text = f\"<start_of_turn>user\\n{prompt}<end_of_turn>\\n<start_of_turn>model\\n\"\n    input_ids = tokenizer.encode(input_text, return_tensors=\"pt\").to(device)\n\n    with torch.no_grad():\n        output = model.generate(input_ids, max_length=len(input_ids[0]) + 50,  # Adjust max_length as needed\n                                 pad_token_id=tokenizer.eos_token_id)\n\n    generated_text = tokenizer.decode(output[0], skip_special_tokens=True)\n    return generated_text.split(\"<start_of_turn>model\\n\")[-1].strip()\n\n# Prompt Generator Agent - Uses Gemma to generate prompts for other agents\nprompt_generator_agent = autogen.AssistantAgent(\n    name='Prompt_Generator',\n    llm_config={},  # No llm_config needed as we are directly calling Gemma\n    system_message=\"\"\"You are an expert prompt engineer. Your task is to generate specific and effective prompts for other AI agents based on the overall task and their individual roles. Understand the context, desired output format, and any constraints. Provide clear and concise instructions to guide their work.\n    \"\"\"\n)\n\n# Planner agent\nplanner_agent = autogen.AssistantAgent(\n    name='Planner',\n    llm_config=llm_config_gpt4,\n    system_message=\"\"\"You are a highly creative and experienced scriptwriting planner. Your task is to generate innovative ideas, detailed outlines, and compelling character and setting designs for scripts. Focus on creating structured and actionable plans that the Writer agent can easily follow.\n    \"\"\"\n)\n\n# Writer agent\nwriter_agent = autogen.AssistantAgent(\n    name='Writer',\n    llm_config=llm_config_gpt4,\n    system_message=\"\"\"You are a skilled and passionate scriptwriter. Your task is to draft engaging chapters based on the provided plan, ensuring a smooth narrative flow and vivid descriptions. Pay close attention to character development, dialogue, and scene-setting.\n    \"\"\"\n)\n\n# Editor agent\neditor_agent = autogen.AssistantAgent(\n    name='Editor',\n    llm_config=llm_config_gpt4,\n    system_message=\"\"\"You are a meticulous and experienced script editor. Your task is to refine drafts for coherence, style, grammar, and pacing, ensuring the script is polished and error-free. Focus on providing constructive feedback and suggestions for improvement.\n    \"\"\"\n)\n\n# Fact-Checker agent\nfact_checker_agent = autogen.AssistantAgent(\n    name='FactChecker',\n    llm_config=llm_config_gpt4,\n    system_message=\"\"\"You are an expert fact-checker with a commitment to accuracy. Your task is to verify the accuracy of the content by cross-referencing information and correcting any inaccuracies. Pay close attention to details and ensure that all facts are supported by evidence.\n    \"\"\"\n)\n\n# Publisher agent\npublisher_agent = autogen.AssistantAgent(\n    name='Publisher',\n    llm_config=llm_config_gpt4,\n    system_message=\"\"\"You are an experienced publisher familiar with industry standards. Your task is to format the manuscript and prepare it for publication, ensuring it meets all necessary requirements. Pay close attention to formatting guidelines, layout, and overall presentation.\n    \"\"\"\n)\n\n# User proxy agent\nuser_proxy = autogen.UserProxyAgent(\n    name='User_Proxy',\n    human_input_mode='NEVER',\n    max_consecutive_auto_reply=5,\n    is_termination_msg=lambda x: x.get('content', '').rstrip().endswith('TERMINATE'),\n    code_execution_config={'work_dir': 'script_writing'},\n    llm_config=llm_config_gpt4,\n    system_message=\"\"\"You are a user proxy agent. You check the plan, execute the code, and report results. Your primary goal is to facilitate the scriptwriting process by coordinating the different agents and ensuring they work together effectively.\n    \"\"\"\n)\n\n# -----------------------------------------------------------------------\n# Workflow Implementation\n# -----------------------------------------------------------------------\n\n# 1. User provides the initial task\ninitial_task = 'Write a script about a group of friends who start a tech company in a small town.'\n\n# 2. Generate prompt for the Planner agent using Gemma\nprompt_generation_task_planner = f\"\"\"\nGenerate a specific prompt for the Planner agent.\nThe Planner agent's role is to generate innovative ideas, detailed outlines, and compelling character and setting designs for the script: '{initial_task}'.\nThe prompt should instruct the Planner to provide a structured and actionable plan that the Writer agent can easily follow.\n\"\"\"\n\n# Generate prompt using Gemma\nplanner_prompt = generate_gemma_text(prompt_generation_task_planner)\n\n# 3. Planner agent executes its task (using GPT-4)\nuser_proxy.send(\n    recipient=planner_agent,\n    message=planner_prompt\n)\n\noutline = planner_agent.last_message[\"content\"]\n\n# 4. Generate prompt for the Writer agent using Gemma\nprompt_generation_task_writer = f\"\"\"\nGenerate a specific prompt for the Writer agent.\nThe Writer agent's role is to draft engaging chapters based on the outline: '{outline}' for the script: '{initial_task}'.\nThe prompt should instruct the Writer to focus on clear and concise prose, compelling dialogue, and vivid descriptions.\n\"\"\"\n\n# Generate prompt using Gemma\nwriter_prompt = generate_gemma_text(prompt_generation_task_writer)\n\n# 5. Writer agent executes its task (using GPT-4)\nuser_proxy.send(\n    recipient=writer_agent,\n    message=writer_prompt\n)\n\n# -----------------------------------------------------------------------\n# Editor Agent Prompt Generation and Execution\n# -----------------------------------------------------------------------\n\n# 8. Generate prompt for the Editor agent using Gemma\nprompt_generation_task_editor = f\"\"\"\nGenerate a specific prompt for the Editor agent.\nThe Editor agent's role is to refine drafts for coherence, style, grammar, and pacing, ensuring the script is polished and error-free. The current chapter is: '{writer_agent.last_message[\"content\"]}'\nThe prompt should instruct the Editor to focus on providing constructive feedback and suggestions for improvement.\nRefer to the manuscript format template from Reedsy Blog to guide edits, look for sentence clarity, and ensure consistent messaging, tone, style, and formatting.\n\"\"\"\n\n# 9. Generate prompt using Gemma\neditor_prompt = generate_gemma_text(prompt_generation_task_editor)\n\n# 10. Editor agent executes its task (using GPT-4)\nuser_proxy.send(\n    recipient=editor_agent,\n    message=editor_prompt\n)\n\n# -----------------------------------------------------------------------\n# Fact-Checker Agent Prompt Generation and Execution\n# -----------------------------------------------------------------------\n\n# 11. Generate prompt for the Fact-Checker agent using Gemma\nprompt_generation_task_factchecker = f\"\"\"\nGenerate a specific prompt for the Fact-Checker agent.\nThe Fact-Checker agent's role is to verify the accuracy of the content by cross-referencing information and correcting any inaccuracies.\nThe current chapter is: '{editor_agent.last_message[\"content\"]}'\nThe prompt should instruct the Fact-Checker to pay close attention to details and ensure that all facts are supported by evidence, using credible and reliable sources.\n\"\"\"\n\n# 12. Generate prompt using Gemma\nfactchecker_prompt = generate_gemma_text(prompt_generation_task_factchecker)\n\n# 13. Fact-Checker agent executes its task (using GPT-4)\nuser_proxy.send(\n    recipient=fact_checker_agent,\n    message=factchecker_prompt\n)\n\n# -----------------------------------------------------------------------\n# Publisher Agent Prompt Generation and Execution\n# -----------------------------------------------------------------------\n\n# 14. Generate prompt for the Publisher agent using Gemma\nprompt_generation_task_publisher = f\"\"\"\nGenerate a specific prompt for the Publisher agent.\nThe Publisher agent's role is to format the manuscript and prepare it for publication, ensuring it meets all necessary requirements.\nThe current chapter is: '{fact_checker_agent.last_message[\"content\"]}'\nThe prompt should instruct the Publisher to pay close attention to formatting guidelines, layout, and overall presentation, ensuring it meets industry standards for manuscript format. Use Reedsy's blog for manuscript format.\n\"\"\"\n\n# 15. Generate prompt using Gemma\npublisher_prompt = generate_gemma_text(prompt_generation_task_publisher)\n\n# 16. Publisher agent executes its task (using GPT-4)\nuser_proxy.send(\n    recipient=publisher_agent,\n    message=publisher_prompt\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-07T14:04:10.490748Z","iopub.status.idle":"2025-04-07T14:04:10.491223Z","shell.execute_reply":"2025-04-07T14:04:10.491040Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"user_proxy.initiate_chat(\n    planner_agent,\n    message='Generate ideas, create outlines, and design characters and settings for a script.'\n)\n\nuser_proxy.send(\n    recipient=writer_agent,\n    message='Draft engaging chapters based on the provided plan.'\n)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-07T14:04:10.492126Z","iopub.status.idle":"2025-04-07T14:04:10.492465Z","shell.execute_reply":"2025-04-07T14:04:10.492336Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"groupchat = autogen.GroupChat(\n    agents=[user_proxy, planner_agent, writer_agent, editor_agent, fact_checker_agent, publisher_agent],\n    messages=[],\n    max_round=50\n)\n\nmanager = autogen.GroupChatManager(llm_config=llm_config, groupchat=groupchat)\n\nuser_proxy.initiate_chat(\n    manager,\n    message='Let\\'s write a script together.'\n)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-07T14:04:10.493355Z","iopub.status.idle":"2025-04-07T14:04:10.493673Z","shell.execute_reply":"2025-04-07T14:04:10.493550Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}