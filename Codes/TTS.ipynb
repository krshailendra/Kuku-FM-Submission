{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[],"dockerImageVersionId":30918,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"from openai import OpenAI\nimport json\n\n# Initialize the OpenAI client\nclient = OpenAI(api_key=\"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\")  # ğŸ” Replace with your key\n\ndef extract_dialogues_with_llm(script: str):\n    response = client.chat.completions.create(\n        model=\"gpt-4\",  # or \"gpt-3.5-turbo\"\n        messages=[\n            {\n                \"role\": \"system\",\n                \"content\": \"You are a helpful assistant. Given a script, extract all lines with their speaker. Output as a list of dictionaries with 'speaker' and 'dialog'. Include narrator lines.\"\n            },\n            {\n                \"role\": \"user\",\n                \"content\": script\n            }\n        ],\n        temperature=0\n    )\n\n    # Get the response text (should be a JSON list)\n    raw_output = response.choices[0].message.content\n\n    try:\n        dialogues = json.loads(raw_output)\n        return dialogues\n    except json.JSONDecodeError:\n        print(\"âš  JSON decode failed. Here's the raw output:\\n\")\n        print(raw_output)\n        return []","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-04-08T09:00:34.490424Z","iopub.execute_input":"2025-04-08T09:00:34.490822Z","iopub.status.idle":"2025-04-08T09:00:36.630876Z","shell.execute_reply.started":"2025-04-08T09:00:34.490784Z","shell.execute_reply":"2025-04-08T09:00:36.629648Z"}},"outputs":[],"execution_count":1},{"cell_type":"code","source":"!pip install kokoro soundfile","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-08T09:00:36.631976Z","iopub.execute_input":"2025-04-08T09:00:36.632367Z","iopub.status.idle":"2025-04-08T09:00:53.175160Z","shell.execute_reply.started":"2025-04-08T09:00:36.632325Z","shell.execute_reply":"2025-04-08T09:00:53.173926Z"}},"outputs":[{"name":"stdout","text":"Collecting kokoro\n  Downloading kokoro-0.9.4-py3-none-any.whl.metadata (21 kB)\nRequirement already satisfied: soundfile in /usr/local/lib/python3.10/dist-packages (0.12.1)\nRequirement already satisfied: huggingface-hub in /usr/local/lib/python3.10/dist-packages (from kokoro) (0.29.0)\nCollecting loguru (from kokoro)\n  Downloading loguru-0.7.3-py3-none-any.whl.metadata (22 kB)\nCollecting misaki>=0.9.4 (from misaki[en]>=0.9.4->kokoro)\n  Downloading misaki-0.9.4-py3-none-any.whl.metadata (19 kB)\nRequirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from kokoro) (1.26.4)\nRequirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from kokoro) (2.5.1+cu121)\nRequirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (from kokoro) (4.47.0)\nRequirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.10/dist-packages (from soundfile) (1.17.1)\nRequirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi>=1.0->soundfile) (2.22)\nCollecting addict (from misaki>=0.9.4->misaki[en]>=0.9.4->kokoro)\n  Downloading addict-2.4.0-py3-none-any.whl.metadata (1.0 kB)\nRequirement already satisfied: regex in /usr/local/lib/python3.10/dist-packages (from misaki>=0.9.4->misaki[en]>=0.9.4->kokoro) (2024.11.6)\nCollecting espeakng-loader (from misaki[en]>=0.9.4->kokoro)\n  Downloading espeakng_loader-0.2.4-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.3 kB)\nCollecting num2words (from misaki[en]>=0.9.4->kokoro)\n  Downloading num2words-0.5.14-py3-none-any.whl.metadata (13 kB)\nCollecting phonemizer-fork (from misaki[en]>=0.9.4->kokoro)\n  Downloading phonemizer_fork-3.3.2-py3-none-any.whl.metadata (48 kB)\n\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m48.3/48.3 kB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hRequirement already satisfied: spacy in /usr/local/lib/python3.10/dist-packages (from misaki[en]>=0.9.4->kokoro) (3.7.5)\nCollecting spacy-curated-transformers (from misaki[en]>=0.9.4->kokoro)\n  Downloading spacy_curated_transformers-2.1.2-py2.py3-none-any.whl.metadata (2.8 kB)\nRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->kokoro) (3.17.0)\nRequirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->kokoro) (2024.12.0)\nRequirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->kokoro) (24.2)\nRequirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->kokoro) (6.0.2)\nRequirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->kokoro) (2.32.3)\nRequirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->kokoro) (4.67.1)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->kokoro) (4.12.2)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.10/dist-packages (from numpy->kokoro) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.10/dist-packages (from numpy->kokoro) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.10/dist-packages (from numpy->kokoro) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.10/dist-packages (from numpy->kokoro) (2025.0.1)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.10/dist-packages (from numpy->kokoro) (2022.0.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.10/dist-packages (from numpy->kokoro) (2.4.1)\nRequirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->kokoro) (3.4.2)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->kokoro) (3.1.4)\nRequirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch->kokoro) (1.13.1)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch->kokoro) (1.3.0)\nRequirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.10/dist-packages (from transformers->kokoro) (0.21.0)\nRequirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers->kokoro) (0.4.5)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->kokoro) (3.0.2)\nRequirement already satisfied: intel-openmp>=2024 in /usr/local/lib/python3.10/dist-packages (from mkl->numpy->kokoro) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.10/dist-packages (from mkl->numpy->kokoro) (2022.0.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.10/dist-packages (from tbb==2022.*->mkl->numpy->kokoro) (1.2.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.10/dist-packages (from mkl_umath->numpy->kokoro) (2024.2.0)\nCollecting docopt>=0.6.2 (from num2words->misaki[en]>=0.9.4->kokoro)\n  Downloading docopt-0.6.2.tar.gz (25 kB)\n  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\nRequirement already satisfied: attrs>=18.1 in /usr/local/lib/python3.10/dist-packages (from phonemizer-fork->misaki[en]>=0.9.4->kokoro) (25.1.0)\nCollecting dlinfo (from phonemizer-fork->misaki[en]>=0.9.4->kokoro)\n  Downloading dlinfo-2.0.0-py3-none-any.whl.metadata (1.1 kB)\nRequirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from phonemizer-fork->misaki[en]>=0.9.4->kokoro) (1.4.2)\nCollecting segments (from phonemizer-fork->misaki[en]>=0.9.4->kokoro)\n  Downloading segments-2.3.0-py2.py3-none-any.whl.metadata (3.5 kB)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->kokoro) (3.4.1)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->kokoro) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->kokoro) (2.3.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->kokoro) (2025.1.31)\nRequirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.10/dist-packages (from spacy->misaki[en]>=0.9.4->kokoro) (3.0.12)\nRequirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from spacy->misaki[en]>=0.9.4->kokoro) (1.0.5)\nRequirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.10/dist-packages (from spacy->misaki[en]>=0.9.4->kokoro) (1.0.11)\nRequirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy->misaki[en]>=0.9.4->kokoro) (2.0.10)\nRequirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy->misaki[en]>=0.9.4->kokoro) (3.0.9)\nRequirement already satisfied: thinc<8.3.0,>=8.2.2 in /usr/local/lib/python3.10/dist-packages (from spacy->misaki[en]>=0.9.4->kokoro) (8.2.5)\nRequirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.10/dist-packages (from spacy->misaki[en]>=0.9.4->kokoro) (1.1.3)\nRequirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.10/dist-packages (from spacy->misaki[en]>=0.9.4->kokoro) (2.5.0)\nRequirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.10/dist-packages (from spacy->misaki[en]>=0.9.4->kokoro) (2.0.10)\nRequirement already satisfied: weasel<0.5.0,>=0.1.0 in /usr/local/lib/python3.10/dist-packages (from spacy->misaki[en]>=0.9.4->kokoro) (0.4.1)\nRequirement already satisfied: typer<1.0.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from spacy->misaki[en]>=0.9.4->kokoro) (0.15.1)\nRequirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.10/dist-packages (from spacy->misaki[en]>=0.9.4->kokoro) (2.11.0a2)\nRequirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from spacy->misaki[en]>=0.9.4->kokoro) (75.1.0)\nRequirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from spacy->misaki[en]>=0.9.4->kokoro) (3.5.0)\nCollecting curated-transformers<3.0.0,>=2.0.0 (from spacy-curated-transformers->misaki[en]>=0.9.4->kokoro)\n  Downloading curated_transformers-2.0.1-py2.py3-none-any.whl.metadata (5.3 kB)\nCollecting curated-tokenizers<3.0.0,>=2.0.0 (from spacy-curated-transformers->misaki[en]>=0.9.4->kokoro)\n  Downloading curated_tokenizers-2.0.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.9 kB)\nINFO: pip is looking at multiple versions of spacy-curated-transformers to determine which version is compatible with other requirements. This could take a while.\nCollecting spacy-curated-transformers (from misaki[en]>=0.9.4->kokoro)\n  Downloading spacy_curated_transformers-2.1.1-py2.py3-none-any.whl.metadata (2.8 kB)\nCollecting spacy (from misaki[en]>=0.9.4->kokoro)\n  Downloading spacy-4.0.0.dev3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (26 kB)\nCollecting spacy-curated-transformers (from misaki[en]>=0.9.4->kokoro)\n  Downloading spacy_curated_transformers-2.0.0-py2.py3-none-any.whl.metadata (2.8 kB)\n  Downloading spacy_curated_transformers-0.3.0-py2.py3-none-any.whl.metadata (2.7 kB)\nCollecting curated-transformers<0.2.0,>=0.1.0 (from spacy-curated-transformers->misaki[en]>=0.9.4->kokoro)\n  Downloading curated_transformers-0.1.1-py2.py3-none-any.whl.metadata (965 bytes)\nCollecting curated-tokenizers<0.1.0,>=0.0.9 (from spacy-curated-transformers->misaki[en]>=0.9.4->kokoro)\n  Downloading curated_tokenizers-0.0.9-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.9 kB)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.10/dist-packages (from intel-openmp>=2024->mkl->numpy->kokoro) (2024.2.0)\nRequirement already satisfied: language-data>=1.2 in /usr/local/lib/python3.10/dist-packages (from langcodes<4.0.0,>=3.2.0->spacy->misaki[en]>=0.9.4->kokoro) (1.3.0)\nRequirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy->misaki[en]>=0.9.4->kokoro) (0.7.0)\nRequirement already satisfied: pydantic-core==2.29.0 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy->misaki[en]>=0.9.4->kokoro) (2.29.0)\nRequirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.10/dist-packages (from thinc<8.3.0,>=8.2.2->spacy->misaki[en]>=0.9.4->kokoro) (0.7.11)\nRequirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from thinc<8.3.0,>=8.2.2->spacy->misaki[en]>=0.9.4->kokoro) (0.1.5)\nRequirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0.0,>=0.3.0->spacy->misaki[en]>=0.9.4->kokoro) (8.1.7)\nRequirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0.0,>=0.3.0->spacy->misaki[en]>=0.9.4->kokoro) (1.5.4)\nRequirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0.0,>=0.3.0->spacy->misaki[en]>=0.9.4->kokoro) (13.9.4)\nRequirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from weasel<0.5.0,>=0.1.0->spacy->misaki[en]>=0.9.4->kokoro) (0.20.0)\nRequirement already satisfied: smart-open<8.0.0,>=5.2.1 in /usr/local/lib/python3.10/dist-packages (from weasel<0.5.0,>=0.1.0->spacy->misaki[en]>=0.9.4->kokoro) (7.0.5)\nCollecting csvw>=1.5.6 (from segments->phonemizer-fork->misaki[en]>=0.9.4->kokoro)\n  Downloading csvw-3.5.1-py2.py3-none-any.whl.metadata (10 kB)\nCollecting isodate (from csvw>=1.5.6->segments->phonemizer-fork->misaki[en]>=0.9.4->kokoro)\n  Downloading isodate-0.7.2-py3-none-any.whl.metadata (11 kB)\nRequirement already satisfied: python-dateutil in /usr/local/lib/python3.10/dist-packages (from csvw>=1.5.6->segments->phonemizer-fork->misaki[en]>=0.9.4->kokoro) (2.9.0.post0)\nCollecting rfc3986<2 (from csvw>=1.5.6->segments->phonemizer-fork->misaki[en]>=0.9.4->kokoro)\n  Downloading rfc3986-1.5.0-py2.py3-none-any.whl.metadata (6.5 kB)\nRequirement already satisfied: uritemplate>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from csvw>=1.5.6->segments->phonemizer-fork->misaki[en]>=0.9.4->kokoro) (4.1.1)\nRequirement already satisfied: babel in /usr/local/lib/python3.10/dist-packages (from csvw>=1.5.6->segments->phonemizer-fork->misaki[en]>=0.9.4->kokoro) (2.16.0)\nCollecting language-tags (from csvw>=1.5.6->segments->phonemizer-fork->misaki[en]>=0.9.4->kokoro)\n  Downloading language_tags-1.2.0-py3-none-any.whl.metadata (2.1 kB)\nCollecting rdflib (from csvw>=1.5.6->segments->phonemizer-fork->misaki[en]>=0.9.4->kokoro)\n  Downloading rdflib-7.1.4-py3-none-any.whl.metadata (11 kB)\nRequirement already satisfied: colorama in /usr/local/lib/python3.10/dist-packages (from csvw>=1.5.6->segments->phonemizer-fork->misaki[en]>=0.9.4->kokoro) (0.4.6)\nRequirement already satisfied: jsonschema in /usr/local/lib/python3.10/dist-packages (from csvw>=1.5.6->segments->phonemizer-fork->misaki[en]>=0.9.4->kokoro) (4.23.0)\nRequirement already satisfied: marisa-trie>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy->misaki[en]>=0.9.4->kokoro) (1.2.1)\nRequirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy->misaki[en]>=0.9.4->kokoro) (3.0.0)\nRequirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy->misaki[en]>=0.9.4->kokoro) (2.19.1)\nRequirement already satisfied: wrapt in /usr/local/lib/python3.10/dist-packages (from smart-open<8.0.0,>=5.2.1->weasel<0.5.0,>=0.1.0->spacy->misaki[en]>=0.9.4->kokoro) (1.17.0)\nRequirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy->misaki[en]>=0.9.4->kokoro) (0.1.2)\nRequirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.10/dist-packages (from jsonschema->csvw>=1.5.6->segments->phonemizer-fork->misaki[en]>=0.9.4->kokoro) (2024.10.1)\nRequirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.10/dist-packages (from jsonschema->csvw>=1.5.6->segments->phonemizer-fork->misaki[en]>=0.9.4->kokoro) (0.35.1)\nRequirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from jsonschema->csvw>=1.5.6->segments->phonemizer-fork->misaki[en]>=0.9.4->kokoro) (0.22.3)\nRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil->csvw>=1.5.6->segments->phonemizer-fork->misaki[en]>=0.9.4->kokoro) (1.17.0)\nRequirement already satisfied: pyparsing<4,>=2.1.0 in /usr/local/lib/python3.10/dist-packages (from rdflib->csvw>=1.5.6->segments->phonemizer-fork->misaki[en]>=0.9.4->kokoro) (3.2.0)\nDownloading kokoro-0.9.4-py3-none-any.whl (32 kB)\nDownloading misaki-0.9.4-py3-none-any.whl (3.6 MB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m3.6/3.6 MB\u001b[0m \u001b[31m35.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading loguru-0.7.3-py3-none-any.whl (61 kB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m61.6/61.6 kB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading addict-2.4.0-py3-none-any.whl (3.8 kB)\nDownloading espeakng_loader-0.2.4-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (10.1 MB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m10.1/10.1 MB\u001b[0m \u001b[31m90.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m0:01\u001b[0m\n\u001b[?25hDownloading num2words-0.5.14-py3-none-any.whl (163 kB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m163.5/163.5 kB\u001b[0m \u001b[31m8.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading phonemizer_fork-3.3.2-py3-none-any.whl (82 kB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m82.7/82.7 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading spacy_curated_transformers-0.3.0-py2.py3-none-any.whl (236 kB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m236.3/236.3 kB\u001b[0m \u001b[31m13.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading curated_tokenizers-0.0.9-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (731 kB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m731.6/731.6 kB\u001b[0m \u001b[31m24.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading curated_transformers-0.1.1-py2.py3-none-any.whl (25 kB)\nDownloading dlinfo-2.0.0-py3-none-any.whl (3.7 kB)\nDownloading segments-2.3.0-py2.py3-none-any.whl (15 kB)\nDownloading csvw-3.5.1-py2.py3-none-any.whl (59 kB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m59.9/59.9 kB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading rfc3986-1.5.0-py2.py3-none-any.whl (31 kB)\nDownloading isodate-0.7.2-py3-none-any.whl (22 kB)\nDownloading language_tags-1.2.0-py3-none-any.whl (213 kB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m213.4/213.4 kB\u001b[0m \u001b[31m11.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading rdflib-7.1.4-py3-none-any.whl (565 kB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m565.1/565.1 kB\u001b[0m \u001b[31m23.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hBuilding wheels for collected packages: docopt\n  Building wheel for docopt (setup.py) ... \u001b[?25l\u001b[?25hdone\n  Created wheel for docopt: filename=docopt-0.6.2-py2.py3-none-any.whl size=13706 sha256=b9a2bb9383ea3990ca57a769f761735b703ab5a7cf25b389789244a286075150\n  Stored in directory: /root/.cache/pip/wheels/fc/ab/d4/5da2067ac95b36618c629a5f93f809425700506f72c9732fac\nSuccessfully built docopt\nInstalling collected packages: rfc3986, language-tags, docopt, addict, num2words, misaki, loguru, isodate, espeakng-loader, dlinfo, curated-tokenizers, rdflib, curated-transformers, spacy-curated-transformers, csvw, segments, phonemizer-fork, kokoro\nSuccessfully installed addict-2.4.0 csvw-3.5.1 curated-tokenizers-0.0.9 curated-transformers-0.1.1 dlinfo-2.0.0 docopt-0.6.2 espeakng-loader-0.2.4 isodate-0.7.2 kokoro-0.9.4 language-tags-1.2.0 loguru-0.7.3 misaki-0.9.4 num2words-0.5.14 phonemizer-fork-3.3.2 rdflib-7.1.4 rfc3986-1.5.0 segments-2.3.0 spacy-curated-transformers-0.3.0\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"import torch\nfrom transformers import AutoTokenizer, BertForSequenceClassification\nimport nltk\n\n# Download punkt if not already\nnltk.download(\"punkt\")\n\n# Load tokenizer and model\ntokenizer = AutoTokenizer.from_pretrained(\"bhadresh-savani/bert-base-go-emotion\")\nmodel = BertForSequenceClassification.from_pretrained(\"bhadresh-savani/bert-base-go-emotion\")\n\n# Define emotion labels\nemotion_labels = [\n    \"admiration\", \"amusement\", \"anger\", \"annoyance\", \"approval\", \"caring\",\n    \"confusion\", \"curiosity\", \"desire\", \"disappointment\", \"disapproval\",\n    \"disgust\", \"embarrassment\", \"excitement\", \"fear\", \"gratitude\", \"grief\",\n    \"joy\", \"love\", \"nervousness\", \"optimism\", \"pride\", \"realization\",\n    \"relief\", \"remorse\", \"sadness\", \"surprise\", \"neutral\"\n]\n\n# Function to detect the dominant emotion of the whole text\ndef detect_emotion(text):\n    inputs = tokenizer(text, return_tensors=\"pt\", truncation=True, padding=True)\n    with torch.no_grad():\n        logits = model(**inputs).logits\n    predicted_class = torch.argmax(logits, dim=1).item()\n    detected_emotion = emotion_labels[predicted_class]\n    return detected_emotion\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-08T09:00:53.176421Z","iopub.execute_input":"2025-04-08T09:00:53.176859Z","iopub.status.idle":"2025-04-08T09:01:32.081593Z","shell.execute_reply.started":"2025-04-08T09:00:53.176813Z","shell.execute_reply":"2025-04-08T09:01:32.079668Z"}},"outputs":[{"name":"stdout","text":"[nltk_data] Downloading package punkt to /usr/share/nltk_data...\n[nltk_data]   Package punkt is already up-to-date!\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/333 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5dd3fa0377fc48e88feaacc74c8ade8a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"23cc71f3b9364d5ba631d71734a405d8"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d2717e3404664373ad97d55b7bd7b948"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6b5c05a9b9dd45ef83ec5009dc7f6c9e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/2.10k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a92623d3334a46a3aea0639dfb555294"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"pytorch_model.bin:   0%|          | 0.00/438M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"09d918f3062f4b4b9bf246c538fffefb"}},"metadata":{}}],"execution_count":3},{"cell_type":"code","source":"from kokoro import KPipeline\nimport soundfile as sf","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-08T09:01:32.083569Z","iopub.execute_input":"2025-04-08T09:01:32.085787Z","iopub.status.idle":"2025-04-08T09:01:34.692642Z","shell.execute_reply.started":"2025-04-08T09:01:32.085738Z","shell.execute_reply":"2025-04-08T09:01:34.691484Z"}},"outputs":[],"execution_count":4},{"cell_type":"code","source":"pipeline = KPipeline(lang_code='a')  # 'a' for American English","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-08T09:01:34.693775Z","iopub.execute_input":"2025-04-08T09:01:34.694121Z","iopub.status.idle":"2025-04-08T09:01:39.827767Z","shell.execute_reply.started":"2025-04-08T09:01:34.694087Z","shell.execute_reply":"2025-04-08T09:01:39.826529Z"}},"outputs":[{"name":"stdout","text":"WARNING: Defaulting repo_id to hexgrad/Kokoro-82M. Pass repo_id='hexgrad/Kokoro-82M' to suppress this warning.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/2.35k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c252f2ddeda043e6810cb198921d518b"}},"metadata":{}},{"name":"stderr","text":"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:123: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/torch/nn/utils/weight_norm.py:143: FutureWarning: `torch.nn.utils.weight_norm` is deprecated in favor of `torch.nn.utils.parametrizations.weight_norm`.\n  WeightNorm.apply(module, name, dim)\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"kokoro-v1_0.pth:   0%|          | 0.00/327M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"fc8b675105444bfabd9e8ad885f8f456"}},"metadata":{}}],"execution_count":5},{"cell_type":"code","source":"import torchaudio\nimport numpy as np\nimport soundfile as sf\n\n\n# Function to map emotions to prosodic changes\ndef emotion_to_speech_params(emotion):\n    \"\"\"Modify pitch, speed, and energy based on emotion.\"\"\"\n    emotion_params = {\n        \"admiration\": {\"pitch\": 1.4, \"speed\": 1.0, \"energy\": 1.5},\n        \"amusement\": {\"pitch\": 1.5, \"speed\": 1.3, \"energy\": 1.6},\n        \"anger\": {\"pitch\": 1.5, \"speed\": 1.8, \"energy\": 2.2},\n        \"annoyance\": {\"pitch\": 1.3, \"speed\": 1.5, \"energy\": 1.7},\n        \"approval\": {\"pitch\": 1.2, \"speed\": 1.0, \"energy\": 1.3},\n        \"caring\": {\"pitch\": 1.0, \"speed\": 0.7, \"energy\": 1.4},\n        \"confusion\": {\"pitch\": 1.4, \"speed\": 0.7, \"energy\": 0.7},\n        \"curiosity\": {\"pitch\": 1.4, \"speed\": 1.3, \"energy\": 1.0},\n        \"desire\": {\"pitch\": 1.3, \"speed\": 0.7, \"energy\": 1.5},\n        \"disappointment\": {\"pitch\": 0.7, \"speed\": 0.7, \"energy\": 0.6},\n        \"disapproval\": {\"pitch\": 0.8, \"speed\": 1.3, \"energy\": 1.4},\n        \"disgust\": {\"pitch\": 0.7, \"speed\": 1.5, \"energy\": 1.5},\n        \"embarrassment\": {\"pitch\": 1.0, \"speed\": 1.4, \"energy\": 0.6},\n        \"excitement\": {\"pitch\": 1.8, \"speed\": 1.8, \"energy\": 2.0},\n        \"fear\": {\"pitch\": 1.5, \"speed\": 1.9, \"energy\": 1.8},\n        \"gratitude\": {\"pitch\": 1.3, \"speed\": 0.7, \"energy\": 1.3},\n        \"grief\": {\"pitch\": 0.5, \"speed\": 0.5, \"energy\": 0.4},\n        \"joy\": {\"pitch\": 1.7, \"speed\": 1.4, \"energy\": 1.8},\n        \"love\": {\"pitch\": 1.3, \"speed\": 0.7, \"energy\": 1.5},\n        \"nervousness\": {\"pitch\": 1.4, \"speed\": 1.7, \"energy\": 0.7},\n        \"optimism\": {\"pitch\": 1.4, \"speed\": 1.3, \"energy\": 1.5},\n        \"pride\": {\"pitch\": 1.5, \"speed\": 1.0, \"energy\": 1.7},\n        \"realization\": {\"pitch\": 1.5, \"speed\": 1.0, \"energy\": 1.3},\n        \"relief\": {\"pitch\": 1.0, \"speed\": 0.7, \"energy\": 0.7},\n        \"remorse\": {\"pitch\": 0.7, \"speed\": 0.6, \"energy\": 0.6},\n        \"sadness\": {\"pitch\": 0.6, \"speed\": 0.6, \"energy\": 0.5},\n        \"surprise\": {\"pitch\": 1.8, \"speed\": 1.5, \"energy\": 1.9},\n        \"neutral\": {\"pitch\": 1.0, \"speed\": 1.0, \"energy\": 1.0}\n    }\n    return emotion_params.get(emotion, {\"pitch\": 1.0, \"speed\": 1.0, \"energy\": 1.0})\n\n# Function to generate speech with a single voice while modifying emotions\ndef generate_speech(parsed_lines):\n    \"\"\"\n    Generate speech from parsed lines using a single base voice while adjusting for emotion.\n\n    Parameters:\n    - parsed_lines: List of tuples [(emotion, sentence), ...]\n\n    Returns:\n    - audio_clips: List of file paths for generated audio clips\n    \"\"\"\n    base_voice = \"af_heart\"  # Use a single voice for all speech\n    audio_clips = []\n\n    for i, (emotion, text) in enumerate(parsed_lines):\n        # Get emotion-based adjustments\n        params = emotion_to_speech_params(emotion)\n\n        # Generate speech with controlled parameters\n        generator = pipeline(text, voice=base_voice, speed=params[\"speed\"], split_pattern=r'\\n+')\n\n        for _, _, audio in generator:\n            # Apply post-processing (adjust pitch & volume)\n            audio = modify_audio(audio, params[\"pitch\"], params[\"energy\"])\n\n            # Save output\n            file_name = f\"output_{i}_{emotion}.wav\"\n            sf.write(file_name, audio, 24000)\n            audio_clips.append(file_name)\n\n    return audio_clips\n\n# Function to modify audio pitch and volume using torchaudio\ndef modify_audio(audio, pitch_factor, energy_factor):\n    \"\"\"Modify pitch and volume to match emotion tone.\"\"\"\n    waveform = torch.tensor(audio, dtype=torch.float32)\n\n    # Convert stereo to mono if necessary\n    if waveform.dim() > 1:\n        waveform = waveform.mean(dim=0)\n\n    # Adjust pitch\n    waveform = torchaudio.functional.pitch_shift(waveform, 24000, n_steps=pitch_factor)\n\n    # Adjust volume safely\n    waveform = torch.clamp(waveform * energy_factor, min=-1.0, max=1.0)\n\n    return waveform.cpu().numpy()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-08T09:01:39.830437Z","iopub.execute_input":"2025-04-08T09:01:39.830862Z","iopub.status.idle":"2025-04-08T09:01:40.978777Z","shell.execute_reply.started":"2025-04-08T09:01:39.830825Z","shell.execute_reply":"2025-04-08T09:01:40.977745Z"}},"outputs":[],"execution_count":6},{"cell_type":"code","source":"def process_script_for_speech(script: str):\n    # Step 1: Extract dialogue lines with LLM\n    dialogue_list = extract_dialogues_with_llm(script)\n\n    # Step 2: Detect emotion for each line\n    emotion_sentence_pairs = []\n    for entry in dialogue_list:\n        speaker = entry.get(\"speaker\", \"Unknown\")\n        dialog = entry.get(\"dialog\", \"\")\n\n        if dialog.strip():  # avoid empty lines\n            emotion = detect_emotion(dialog)\n            emotion_sentence_pairs.append((emotion, dialog))\n\n    return emotion_sentence_pairs\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-08T09:01:40.980102Z","iopub.execute_input":"2025-04-08T09:01:40.980562Z","iopub.status.idle":"2025-04-08T09:01:40.986237Z","shell.execute_reply.started":"2025-04-08T09:01:40.980524Z","shell.execute_reply":"2025-04-08T09:01:40.985068Z"}},"outputs":[],"execution_count":7},{"cell_type":"code","source":"script_text = final_script = \"\"\"A lush, vibrant forest path. Forest creatures have gathered around the HARE, a tall, sleek creature with boastful eyes, and the TORTOISE, a small, steady figure with a serene aura.\n\nHARE: (Smugly, to the crowd) \"I bet I could outpace any one of you in a race. Especially you, Tortoise.\" (Laughs mockingly)\n\n(The HARE points a dismissive paw at the TORTOISE, who simply smiles back, nodding in serene acceptance.)\n\nTORTOISE: (Softly, to Hare, with a knowing smile) \"We'll see, Hare. Let's race.\"\n\n(The HARE laughs uproariously, his chest puffing out in overconfidence as they line up at the starting point.)\n\nHARE: (Chuckling arrogantly) \"Prepare to eat my dust, Tortoise!\"\n\n(The race begins. The HARE darts forward with lightning speed, leaving the TORTOISE at the starting line.)\n\nHARE: (Calling back, tauntingly) \"Hope you're enjoying the view!\"\n\n(Feeling overconfident, the HARE decides to rest under a large, shady tree. He lounges comfortably, smirking at the thought of the TORTOISE lagging far behind, and drifts to sleep. The TORTOISE, meanwhile, plods on, undeterred.)\n\n(HOURS PASS. The sun traces its path across the sky as the TORTOISE maintains his unwavering pace. The HARE, oblivious, snores under the tree.)\n\n(The HARE wakes up suddenly, noticing the sun's position. He looks around, panic surging as he spots the TORTOISE nearing the finish line. He springs up and dashes towards the finish line, but it's too late. The TORTOISE crosses the finish line, greeted with enthusiastic cheers from the forest crowd.)\n\n(The HARE skids to a halt, his eyes wide in stunned disbelief. The TORTOISE turns towards him, a gentle smile playing on his weathered face.)\n\nTORTOISE: (Wisely, with a gentle chuckle) \"Slow and steady, Hare. Remember that.\"\n\n(FADE OUT: The forest path is bathed in twilight hues. The HARE is left staring after the TORTOISE, his earlier arrogance replaced with newfound humility.)\n\nNARRATOR: (Voiceover, reflectively) \"And thus, the Hare learned a valuable lesson that day. Overconfidence can lead to one's downfall, but slow and steady indeed wins the race.\"\n\"\"\"\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-08T09:01:52.711077Z","iopub.execute_input":"2025-04-08T09:01:52.711525Z","iopub.status.idle":"2025-04-08T09:01:52.716615Z","shell.execute_reply.started":"2025-04-08T09:01:52.711482Z","shell.execute_reply":"2025-04-08T09:01:52.715347Z"}},"outputs":[],"execution_count":8},{"cell_type":"code","source":"# Process the script\nparsed = process_script_for_speech(script_text)\n\n# Send to speech generator\naudio_files = generate_speech(parsed)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-08T09:01:55.519125Z","iopub.execute_input":"2025-04-08T09:01:55.519649Z","iopub.status.idle":"2025-04-08T09:03:38.581639Z","shell.execute_reply.started":"2025-04-08T09:01:55.519606Z","shell.execute_reply":"2025-04-08T09:03:38.580420Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"af_heart.pt:   0%|          | 0.00/523k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"fa080d9dd86f46e2aed07894f38c15f4"}},"metadata":{}},{"name":"stderr","text":"<ipython-input-6-9e04a225f7f4>:76: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  waveform = torch.tensor(audio, dtype=torch.float32)\n","output_type":"stream"}],"execution_count":9},{"cell_type":"code","source":"!pip install pydub","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-08T09:03:38.583182Z","iopub.execute_input":"2025-04-08T09:03:38.583633Z","iopub.status.idle":"2025-04-08T09:03:42.894451Z","shell.execute_reply.started":"2025-04-08T09:03:38.583591Z","shell.execute_reply":"2025-04-08T09:03:42.893170Z"}},"outputs":[{"name":"stdout","text":"Requirement already satisfied: pydub in /usr/local/lib/python3.10/dist-packages (0.25.1)\n","output_type":"stream"}],"execution_count":10},{"cell_type":"code","source":"from pydub import AudioSegment\n\ndef merge_audio_files(audio_clips, output_file=\"final_output_1.wav\"):\n    \"\"\"\n    Merge a list of audio files in order and save as a single output file.\n\n    Parameters:\n    - audio_clips: List of audio file paths (ordered)\n    - output_file: Name of the final merged audio file\n\n    Returns:\n    - output_file: Path of the final merged file\n    \"\"\"\n    combined_audio = AudioSegment.empty()  # Start with an empty audio segment\n\n    for file in audio_clips:\n        audio = AudioSegment.from_wav(file)  # Load each audio file\n        combined_audio += audio  # Append to the combined audio\n\n    combined_audio.export(output_file, format=\"wav\")  # Save final file\n    return output_file\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-08T09:03:42.896512Z","iopub.execute_input":"2025-04-08T09:03:42.896877Z","iopub.status.idle":"2025-04-08T09:03:42.946051Z","shell.execute_reply.started":"2025-04-08T09:03:42.896845Z","shell.execute_reply":"2025-04-08T09:03:42.945013Z"}},"outputs":[],"execution_count":11},{"cell_type":"code","source":"final_audio_file = merge_audio_files(audio_files)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-08T09:04:12.649660Z","iopub.execute_input":"2025-04-08T09:04:12.649987Z","iopub.status.idle":"2025-04-08T09:04:12.659804Z","shell.execute_reply.started":"2025-04-08T09:04:12.649961Z","shell.execute_reply":"2025-04-08T09:04:12.658687Z"}},"outputs":[],"execution_count":13},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}