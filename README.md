# ğŸš€ Multi-Agentic Prompt-to-Content (Audio + Video) Generation Pipeline

---

## ğŸ¤– How Our Solution Automates Content Generation for Kuku FM

Our multi-agentic pipeline provides a comprehensive, fully automated content generation system tailored for Kuku FMâ€™s needs:

- **ğŸ” End-to-End Workflow:** The entire journey from prompt or idea to final audio-visual output is automated, requiring minimal human intervention. This matches Kuku FMâ€™s vision of scaling content production using generative AI.
- **ğŸ‘¥ Multi-Agent Collaboration:** By leveraging specialized GPT-4 agents for ideation, writing, editing, and fact-checking, the system ensures each piece of content is creative, coherent, and accurate.
- **ğŸ­ Emotionally-Rich Narration:** Automated emotion tagging with BERT and expressive voice synthesis using Kokoro-82M bring human-like emotion and engagement to each story, elevating listener experience.
- **ğŸ¶ Personalized Audio Editing:** Background music, silence removal, and fade effects are dynamically applied based on detected emotions, ensuring polished and immersive audio quality.
- **âš¡ Rapid Turnaround & Scale:** The pipeline can operate 24/7, generating hundreds or thousands of scripts and corresponding audio episodes daily, supporting Kuku FMâ€™s goal of scalable, personalized content creation.
- **ğŸ–¼ï¸ Seamless Visual Integration:** Thumbnails and synchronized visuals are generated automatically, enabling rapid production of engaging audio-visual content for social media and in-app promotion.
- **ğŸ’¸ Reduced Costs & Faster Time-to-Market:** By automating routine content creation tasks, Kuku FM can significantly reduce reliance on large creative teams while maintaining high content quality and variety.

Together, these features make our solution a perfect fit for Kuku FMâ€™s mission to use generative AI for scalable, high-quality, and engaging audio content that attracts and retains listeners at scale.

---

![Pipeline Diagram](https://github.com/user-attachments/assets/cea709c7-cd75-4e41-86f7-a7ed76f2de21)

This project implements an end-to-end system for transforming textual prompts into audio-synchronized videos with expressive speech, stylized visuals, and precise narration alignment. The architecture leverages multi-agent LLMs, deep learning-based speech and emotion models, and advanced audio-visual processing. Below, we map every pipeline block (see diagram above) to the codebase and describe the technical components.

---

> **ğŸ—‚ï¸ Output Samples:**  
All generated outputsâ€”including finalized scripts, audio files, and video samples from the automated pipelineâ€”are available for review in the following Google Drive folder: [Project Outputs on Google Drive](https://drive.google.com/drive/folders/1pYmqrKBPigrozc9iqW0ZCftgiU7IyKNa).  
This repository of outputs demonstrates the end-to-end capabilities of our system, showcasing examples of emotion-tagged scripts, expressive audio narration, audio-visual synchronization, and stylized thumbnails as produced by each stage of the pipeline.

---

## 1ï¸âƒ£ Input

- **Types:** Prompt (text), Audio+Text, Audio+Script
- **Entry Point:** User provides a prompt or a combination of audio and text/script.

---

## 2ï¸âƒ£ Multi-Agentic Script Writer

- **Code:** [`Codes/Multiagentic Script Writer.ipynb`](Codes/Multiagentic%20Script%20Writer.ipynb)
- **Description:** Uses AutoGen to orchestrate 6 GPT-4-based agents, each responsible for a specific aspect of script generation (plot, dialogue, consistency, fact-checking, etc.).
- **Technical highlights:**
    - ğŸ§  AutoGen LLM orchestration (`pyautogen`, `autogen-agentchat`)
    - ğŸ¤ Modular agent roles for coherence and creativity
    - âœï¸ Output: Draft script

---

## 3ï¸âƒ£ Script Finaliser

- **Code:** [`Codes/Script Finaliser.ipynb`](Codes/Script%20Finaliser.ipynb)
- **Description:** Finalizes the draft script, injecting emotion markers and refining for audio effects.
- **Technical highlights:**
    - ğŸ§‘â€ğŸ’» Emotion classification using BERT (`j-hartmann/emotion-english-distilroberta-base`)
    - ğŸ¬ Effect phrase mapping for expressive narration
    - ğŸ“œ Output: Finalized script with embedded effects

---

## 4ï¸âƒ£ Script Parsing & Reporting

- **Code:** [`Codes/Script Parser Report Generator.ipynb`](Codes/Script%20Parser%20Report%20Generator.ipynb)
- **Description:** Analyzes the finalized script to extract structure, cues, and metadata for downstream processing.
- **Technical highlights:**
    - ğŸ“„ Scripting parsing and structure analysis
    - ğŸ” LangChain & FAISS for document handling

---

## 5ï¸âƒ£ Thumbnail Generation & Style Transfer

- **Block:** Thumbnail Generator â†’ Style Transfer GAN
- **Description:** Generates multiple thumbnail styles using GAN-based transfer for visual diversity.
- **ğŸ–Œï¸ (Code for these blocks not explicitly found, but referenced in your design.)**

---

## 6ï¸âƒ£ TTS (Text-to-Speech) & Audio Synthesis

- **Code:** [`Codes/TTS.ipynb`](Codes/TTS.ipynb)
- **Description:** Converts script (with emotion tags) into expressive speech using TTS models (e.g., Kokoro-82M, OpenAI TTS).
- **Technical highlights:**
    - ğŸ—£ï¸ Emotion-synchronized voice synthesis
    - ğŸ¤ Integration with BERT emotion tags for prosody control

---

## 7ï¸âƒ£ Audio Editing

- **Code:** [`Codes/Audio Editor.ipynb`](Codes/Audio%20Editor.ipynb)
- **Description:** Post-processes audio for background overlays, silence removal, and fade effects using `pydub`.
- **Technical highlights:**
    - ğŸµ Automated background/music overlay
    - âœ‚ï¸ Silence trimming, fade-in/out for naturalness

---

## 8ï¸âƒ£ Transcription

- **Code:** [`Codes/Transcriber.ipynb`](Codes/Transcriber.ipynb)
- **Description:** Uses Whisper for accurate speech-to-text, enabling precise alignment of audio and script.
- **Technical highlights:**
    - ğŸ”Š OpenAI Whisper for robust ASR
    - â±ï¸ Output: segmented, timestamped transcripts

---

## 9ï¸âƒ£ Voice Cloning

- **Block:** Voice Cloner (details not in notebooks)
- **Description:** Clones voice for narration, ensuring consistency and personalization.

---

## ğŸ”Ÿ Audio Effects

- **Block:** Audio Effects (detailed in Audio Editor)
- **Description:** Adds further audio enhancements to the final track.

---

## 1ï¸âƒ£1ï¸âƒ£ Synchronizer & Synchronized Visuals

- **Block:** ITS Synchronizer â†’ Synchronized Visuals
- **Description:** Aligns script, audio, and visuals frame-by-frame (~24fps) for coherent video output.
- **Technical highlights:**
    - ğŸ¬ Uses transcript timing to synchronize generated visuals (e.g., via Stable Diffusion)
    - ğŸï¸ Automated thumbnail and scene style transfer for each segment

---

## 1ï¸âƒ£2ï¸âƒ£ Output

- **Final Products:**
    - ğŸ§ **Audio:** Emotion-rich narration, background effects, and voice cloning
    - ğŸï¸ **Video:** Synchronized visuals and thumbnails generated per script scene
    - ğŸ¤– **All outputs are fully automated and scalable**

---

## ğŸ”¢ Key Technical Numbers

- **6 specialized GPT-4 agents** (AutoGen) for script generation
- **BERT-based emotion tagging** for every script segment
- **Kokoro-82M TTS** for high-fidelity, emotion-synced narration
- **Whisper ASR** for frame-accurate transcript alignment
- **24fps** video generation for smooth, natural output

---

## ğŸ“š References

- See pipeline diagram above for the full architecture and flow.
- Notebooks are modular; each can be executed and tested independently.
- For more details on each block, refer to the respective Jupyter notebook.
